{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_graph(id, simplify=True):\n",
    "    gdf = ox.geocode_to_gdf(id, by_osmid=True)\n",
    "    polygon_boundary = gdf.unary_union\n",
    "    graph = ox.graph_from_polygon(polygon_boundary,\n",
    "                                  network_type='drive',\n",
    "                                  simplify=simplify)\n",
    "    G = nx.Graph(graph)\n",
    "    H = nx.Graph()\n",
    "    # Добавляем рёбра в новый граф, копируя только веса\n",
    "    for u, d in G.nodes(data=True):\n",
    "        H.add_node(u, x=d['x'], y=d['y'])\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        H.add_edge(u, v, length=d['length'])\n",
    "\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\graphs\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись графа в файл GraphML\n",
    "    file_path = os.path.join(directory, f\"graph_{id}.graphml\")\n",
    "    nx.write_graphml(H, file_path)\n",
    "    \n",
    "    print(f\"Граф с id {id} был сохранён в {file_path}\")\n",
    "    H.graph['id'] = id\n",
    "    return H\n",
    "\n",
    "def percent(l, p=0.1, max_points=10):\n",
    "    res = int(len(l) * p) if len(l) * p >= 1 else 1\n",
    "    if res > max_points:\n",
    "        res = 10\n",
    "    return res\n",
    "\n",
    "def find_points_for_experiment(G_cl, clusters, min_length=5, p=0.1, max_points=2):\n",
    "    # словарь хранит в себе {id_кластер: {other_кластер: расстояние до него}}\n",
    "    d = dict(nx.all_pairs_dijkstra_path_length(G_cl))\n",
    "    df = pd.DataFrame(d)\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    df = df.sort_index()\n",
    "    graph_path_length = df.values\n",
    "    res = []\n",
    "\n",
    "    for com_1 in range(len(graph_path_length)):\n",
    "        for com_2 in range(com_1 + 1, len(graph_path_length)):\n",
    "            if graph_path_length[com_1][com_2] >= min_length:\n",
    "                 list_1 = random.sample(clusters[com_1],\n",
    "                                        k=percent(clusters[com_1], p, max_points))\n",
    "                 list_2 = random.sample(clusters[com_2],\n",
    "                                        k=percent(clusters[com_2], p, max_points))\n",
    "                 all_lists = itertools.product(list_1, list_2)\n",
    "\n",
    "                 res.extend(list(all_lists))\n",
    "    return res\n",
    "\n",
    "def create_G_centroid(H):\n",
    "  # Запись данных - {кластер: [ids точек]}\n",
    "  clusters = {}\n",
    "  for node, data in H.nodes(data=True):\n",
    "      cluster = data['cluster']\n",
    "      if cluster not in clusters:\n",
    "          clusters[cluster] = []\n",
    "      clusters[cluster].append(node)\n",
    "\n",
    "  # Определение соседей для каждого кластера\n",
    "  # {id кластера: [ids кластеров соседей]}\n",
    "  cluster_transitions = {}\n",
    "  for cluster, nodes in clusters.items():\n",
    "      neighboring_clusters = set()\n",
    "      for node in nodes:\n",
    "          for neighbor in H.neighbors(node):\n",
    "              neighbor_cluster = H.nodes[neighbor]['cluster']\n",
    "              if neighbor_cluster != cluster:\n",
    "                  neighboring_clusters.add(neighbor_cluster)\n",
    "      cluster_transitions[cluster] = list(neighboring_clusters)\n",
    "\n",
    "  # Поиск центроид каждого кластера\n",
    "  dict_centroid = {}\n",
    "  for i in range(len(clusters)):\n",
    "    nodes_ = [node for node, data in H.nodes(data=True) if data.get('cluster') == i]\n",
    "    s = H.subgraph(nodes_)\n",
    "    closeness_centrality = nx.closeness_centrality(s)\n",
    "    centroid = max(closeness_centrality, key=closeness_centrality.get)\n",
    "    dict_centroid[i] = centroid\n",
    "\n",
    "  # Создаем граф из словаря\n",
    "  G = nx.Graph()\n",
    "  for node, neighbors in cluster_transitions.items():\n",
    "      for neighbor in neighbors:\n",
    "        nodes_ = [n for n, data in H.nodes(data=True) if data.get('cluster') in (node, neighbor)]\n",
    "        s = H.subgraph(nodes_)\n",
    "        length, path = nx.single_source_dijkstra(H,\n",
    "                                                  dict_centroid[node],\n",
    "                                                  dict_centroid[neighbor],\n",
    "                                                  weight='length')\n",
    "        G.add_edge(node, neighbor, weight=length)\n",
    "  return G, clusters\n",
    "\n",
    "def louvain_clusters(H, seed=0, weight='length', resolution=1):\n",
    "    communities = nx.community.louvain_communities(H, seed=seed,\n",
    "                                                weight=weight,\n",
    "                                                resolution=resolution)\n",
    "    for i, ids in enumerate(communities):\n",
    "        for j in ids:\n",
    "            H.nodes[j]['cluster'] = i\n",
    "    return H, communities\n",
    "\n",
    "def create_points_for_test(H, min_distance=10):\n",
    "    H, _ = louvain_clusters(H, resolution=1, weight='length') # \n",
    "    G_centroid, clusters = create_G_centroid(H)\n",
    "    random.seed(1)\n",
    "    res = find_points_for_experiment(G_centroid, clusters, min_distance)\n",
    "    return res\n",
    "\n",
    "def formula_centroid(v0, e0, e1, k):\n",
    "    return e1 * math.log(k*v0) + v0 + (e0/math.sqrt(k*v0) * (math.log(math.sqrt(v0/k))))\n",
    "\n",
    "def formula_louven(H):\n",
    "    m = len(H.nodes())\n",
    "    n = len(H.edges())\n",
    "    return (n*math.log(n) + m*math.log(n))\n",
    "\n",
    "def search_resolutions(H, resolution=0.001, weight='length', k_max=0.7):\n",
    "    resolutions = []\n",
    "    k = 0\n",
    "    ks = []\n",
    "    v1 = []\n",
    "    e1  =[]\n",
    "\n",
    "    while k < k_max:\n",
    "      H, communities = louvain_clusters(H, resolution=resolution, weight=weight)\n",
    "      k = len(communities)/len(H.nodes)\n",
    "    #   print(f'a = {len(communities)/len(H.nodes):>6.9f},\\tresolution = {resolution:>10.3f}')\n",
    "      if k < 0.008:\n",
    "        resolution *= 3\n",
    "        continue\n",
    "      else:\n",
    "        G_centroid, _ = create_G_centroid(H)\n",
    "        if len(G_centroid.nodes()) > 0 and len(G_centroid.edges()) > 0:\n",
    "          v1.append(len(G_centroid.nodes()))\n",
    "          e1.append(len(G_centroid.edges()))\n",
    "          resolutions.append(resolution)\n",
    "          ks.append(k)\n",
    "          resolution *= 3\n",
    "\n",
    "\n",
    "    return resolutions, ks, v1, e1\n",
    "\n",
    "def visualisation(H, v1, e1, show=False):\n",
    "    v0 = len(H.nodes())\n",
    "    e0 = len(H.edges())\n",
    "\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "\n",
    "    for i in range(len(v1)):\n",
    "        vi = v1[i]\n",
    "        ei = e1[i]\n",
    "        k = vi/v0\n",
    "        y = formula_centroid(v0, e0, ei, k)  # Убедитесь, что функция formula_centroid определена\n",
    "        x_values.append(round(k, 3))\n",
    "        y_values.append(y)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.plot(x_values, y_values, 'ro-', label='Асимптотическое время')  # Добавляем метку для красных точек\n",
    "    plt.xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.ylabel('Эволюция асимптотического времени')\n",
    "    plt.title('Асимптотическое время работы')\n",
    "\n",
    "    # Вызываем функцию formula_louven и добавляем горизонтальную линию\n",
    "    louven_value = formula_louven(H)\n",
    "    plt.axhline(y=louven_value, color='g', linestyle='--', label='Алгоритм Лувена')  # Добавляем метку для горизонтальной линии\n",
    "    plt.legend()  # Отображаем легенду на графике\n",
    "\n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись графа в файл GraphML\n",
    "    file_path = os.path.join(directory, f\"асимптота_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График асимптоты был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def test(H: nx.Graph, resolutions: list, k: int=100, min_distance: int=10, weight:str='length'):\n",
    "\n",
    "    res = create_points_for_test(H, min_distance=min_distance)\n",
    "\n",
    "    output = {\n",
    "        'error': [],\n",
    "        'time_centr': [],\n",
    "        'times': [],\n",
    "        'ks': [],\n",
    "    }\n",
    "\n",
    "    mistakes = {\n",
    "      \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        part = random.sample(res, k=k)\n",
    "    except ValueError:\n",
    "        part = res  # Если k больше размера популяции или отрицательно, используем весь список\n",
    "\n",
    "    start = time.time()\n",
    "    all_length = []\n",
    "    print('\\nТестирование на начальном графе:')\n",
    "    for i in tqdm(part):\n",
    "        length, path1 = nx.single_source_dijkstra(H, i[0], i[1], weight=weight)\n",
    "        all_length.append(length)\n",
    "    end = time.time()\n",
    "    output['dijkstra_time'] = end - start\n",
    "\n",
    "    v1 = []\n",
    "    e1  =[]\n",
    "\n",
    "    print('\\nТестирование на центроидах:')\n",
    "    for resolution in resolutions:\n",
    "        H, communities = louvain_clusters(H, resolution=resolution, weight=weight)\n",
    "        k = len(communities)/len(H.nodes)\n",
    "        output['ks'].append(round(k, 3))\n",
    "\n",
    "        start_centr = time.time()\n",
    "        G_centroid, clusters = create_G_centroid(H)\n",
    "        end_centr = time.time() - start_centr\n",
    "        output['time_centr'].append(end_centr)\n",
    "        v1.append(len(G_centroid.nodes()))\n",
    "        e1.append(len(G_centroid.edges()))\n",
    "\n",
    "        all_l_c = []\n",
    "        start = time.time()\n",
    "        for i in tqdm(part):\n",
    "\n",
    "            cluster_1 = H.nodes(data=True)[i[0]]['cluster']\n",
    "            cluster_2 = H.nodes(data=True)[i[1]]['cluster']\n",
    "            leng_G = nx.dijkstra_path(G_centroid, cluster_1, cluster_2)\n",
    "            nodes = []\n",
    "            for g_name in leng_G:\n",
    "                nodes.extend(clusters[g_name])\n",
    "            Hs = H.subgraph(nodes)\n",
    "            length,path2 = nx.single_source_dijkstra(Hs, i[0], i[1], weight='length')\n",
    "\n",
    "            all_l_c.append(length)\n",
    "\n",
    "        result = time.time() - start\n",
    "        output['times'].append(result)\n",
    "        mis = (np.array(all_l_c).sum() - np.array(all_length).sum()) / np.array(all_length).sum() * 100\n",
    "        mis_box_plot = (np.array(all_l_c) - np.array(all_length)) / np.array(all_length) * 100\n",
    "        mistakes[round(k, 3)] = mis_box_plot\n",
    "        output['error'].append(mis)\n",
    "        \n",
    "    output = pd.DataFrame(output)\n",
    "    mistakes = pd.DataFrame(mistakes)\n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\csv\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись CSV\n",
    "    file_path_output = os.path.join(directory, f\"output_{H.graph['id']}.csv\")\n",
    "    file_path_mistakes = os.path.join(directory, f\"mistakes_{H.graph['id']}.csv\")\n",
    "\n",
    "    output.to_csv(file_path_output, index=False)\n",
    "    print(f\"output_{H.graph['id']}.csv был сохранён в {file_path_output}\")\n",
    "    \n",
    "    mistakes.to_csv(file_path_mistakes, index=False)\n",
    "    print(f\"mistakes_{H.graph['id']}.csv был сохранён в {file_path_mistakes}\")\n",
    "\n",
    "    return output, mistakes\n",
    "\n",
    "def box_visualisation(H, output, mistakes, y=10, show=False):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    ax1 = mistakes.boxplot(showfliers=False, grid=False)\n",
    "    plt.xticks(range(1, len(mistakes.columns)+1), mistakes.columns)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(1, len(output['times'])+1), output['times'], 'ro-')\n",
    "    \n",
    "    # Добавляем горизонтальную линию на уровне y\n",
    "    ax1.axhline(y=y, color='g', linestyle='--')\n",
    "    \n",
    "    # Устанавливаем подписи для осей\n",
    "    ax1.set_ylabel('Ошибки, %', color='b')\n",
    "    ax2.set_ylabel('Время, сек', color='r')\n",
    "    # Устанавливаем цвета для осей\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color('b')\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color('r')\n",
    "    ax1.set_xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.title('Поиск оптимального отношения кластеров к кол-ву узлов в графе')\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data\\img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись PNG\n",
    "    file_path = os.path.join(directory, f\"boxplot_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График boxplot был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def box_visualisation(H, output, mistakes, y=10, show=False):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    ax1 = mistakes.boxplot(showfliers=False, grid=False)\n",
    "    plt.xticks(range(1, len(mistakes.columns)+1), mistakes.columns)\n",
    "    ax2 = ax1.twinx()\n",
    "    # Добавляем метку для линейного графика, чтобы использовать её в легенде\n",
    "    line1, = ax2.plot(range(1, len(output['times'])+1), output['times'], 'ro-', label='Время работы')\n",
    "    \n",
    "    # Добавляем горизонтальную линию на уровне y, также с меткой\n",
    "    line2 = ax1.axhline(y=y, color='g', linestyle='--', label='Желаемая ошибка')\n",
    "    \n",
    "    # Устанавливаем подписи для осей\n",
    "    ax1.set_ylabel('Ошибки, %', color='b')\n",
    "    ax2.set_ylabel('Время, сек', color='r')\n",
    "    \n",
    "    # Устанавливаем цвета для осей\n",
    "    for tl in ax1.get_yticklabels():\n",
    "        tl.set_color('b')\n",
    "    for tl in ax2.get_yticklabels():\n",
    "        tl.set_color('r')\n",
    "    \n",
    "    ax1.set_xlabel('k, отношение кластеров к узлам графа')\n",
    "    plt.title('Поиск оптимального отношения кластеров к кол-ву узлов в графе')\n",
    "    \n",
    "    # Добавляем легенду\n",
    "    lines = [line1, line2]\n",
    "    ax1.legend(lines, [l.get_label() for l in lines])\n",
    "    \n",
    "    # Создание папки, если она не существует\n",
    "    directory = \"data/img\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    # Запись PNG\n",
    "    file_path = os.path.join(directory, f\"boxplot_{H.graph['id']}.png\")\n",
    "    plt.savefig(file_path, dpi=120)\n",
    "    \n",
    "    print(f\"График boxplot был сохранён в {file_path}\")\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_cities_with_population_greater_than_n(n):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = \"\"\"\n",
    "        [out:json];\n",
    "        (\n",
    "            relation[\"place\"=\"city\"];\n",
    "            relation[\"place\"=\"town\"];\n",
    "            relation[\"place\"=\"village\"];\n",
    "        );\n",
    "        out;\n",
    "    \"\"\"\n",
    "    response = requests.get(overpass_url, params={\"data\": overpass_query})\n",
    "    data = response.json()\n",
    "\n",
    "    result = {\n",
    "        'cities': [],\n",
    "        'city_ids': [],\n",
    "        'population_list': [],\n",
    "        'place': []\n",
    "    }\n",
    "\n",
    "    for element in tqdm(data[\"elements\"], leave=False):\n",
    "        if \"population\" in element[\"tags\"]:\n",
    "            population = element[\"tags\"][\"population\"].replace(\" \", \"\")\n",
    "            try:\n",
    "                population = int(population)\n",
    "                if population >= n:\n",
    "                    if \"name\" in element[\"tags\"]:\n",
    "                        result['cities'].append(element['tags']['name'])  # Добавляем название города в список городов\n",
    "                        result['city_ids'].append(element['id'])  # Добавляем идентификатор в список идентификаторов\n",
    "                        result['population_list'].append(element[\"tags\"][\"population\"].replace(\" \", \"\"))\n",
    "                        result['place'].append(element['tags']['place'])\n",
    "            except ValueError:\n",
    "                # Здесь можно добавить логирование или другую обработку ошибок\n",
    "                print(f\"Не удалось преобразовать население в число для {element['tags'].get('name', 'неизвестного города')}\")\n",
    "    \n",
    "    return pd.DataFrame(result)  # Возвращаем оба списка    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    min_population = 30000  # Задайте минимальное население\n",
    "    result = get_cities_with_population_greater_than_n(min_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(result['city_ids'].apply(lambda x: 'R'+str(x)))                      # Тут все id для теста\n",
    "\n",
    "for id in ids[:1]:\n",
    "    try:\n",
    "        H = download_graph(id, simplify=True)                                   # Загрузка графа\n",
    "        resolutions, ks, v1, e1 = search_resolutions(H, k_max=0.6)              # Находим набор рабочих resolutions, ks, (v1, e1) для каждого графа\n",
    "        visualisation(H, v1, e1)                                                # Визуализация времени работы по ks и формуле\n",
    "        output, mistakes = test(H, resolutions, k=5, weight='length')           # Тест графа\n",
    "        box_visualisation(H, output, mistakes)                                  # Визуализация ошибки boxplot`ом\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при обработке графа с id {id}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SBER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
